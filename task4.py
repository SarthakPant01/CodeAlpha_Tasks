# -*- coding: utf-8 -*-
"""TASK4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mZGDrXT0IudKFQsdySpkbLeU3S4A5Pkh

Read in Data and NLTK basics
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use("ggplot")

import nltk

"""Read the data"""

#Read the data

df = pd.read_csv('/content/data2.csv')

from google.colab import drive
drive.mount('/content/drive')

df.head()

#Reviewing the text on the first position\


df['Text'].values[0]

print(df.shape)
df = df.head(500)
print(df.shape)

#EDA

ax = df['Score'].value_counts().sort_index().plot(kind='bar', title='Count of Reviews by Stars', figsize=(10,5), color = 'orange')

ax.set_xlabel('Review Stars')
plt.show()

"""NLTK review"""

example = df['Text'][50]
print (example)

import nltk
nltk.download('punkt_tab')
tokens = nltk.word_tokenize(example)
tokens[:10]

nltk.download('averaged_perceptron_tagger_eng')
nltk.pos_tag(tokens)

"""VADER Sentiment"""

from nltk.sentiment import SentimentIntensityAnalyzer
from tqdm.notebook import tqdm

import nltk
nltk.download('vader_lexicon')

sia = SentimentIntensityAnalyzer()

sia.polarity_scores('I am so happy!')

sia.polarity_scores('This product is faulty')

sia.polarity_scores(example)

#Run the polarity score on the entire dataset

res = {}
for i, row in tqdm(df.iterrows(), total=len(df)):
    text = row['Text']
    myid = row['Id']
    res[myid] = sia.polarity_scores(text)

res

vaders = pd.DataFrame(res).T
vaders = vaders.reset_index().rename(columns={'index': 'Id'})
vaders = vaders.merge(df, how='left')

vaders

#Sentiment Score and metadata

vaders.head()

"""VADER Results"""

ax = sns.barplot(data=vaders, x='Score', y='compound', palette='bright')
ax.set_title('Compound Score by Amazon Star Review')
plt.show()

fig, axs = plt.subplots(1, 3, figsize=(12, 3))
sns.barplot(data=vaders, x='Score', y='pos', palette='deep', ax=axs[0])
sns.barplot(data=vaders, x='Score', y='neu', palette='deep', ax=axs[1])
sns.barplot(data=vaders, x='Score', y='neg', palette='deep', ax=axs[2])
axs[0].set_title('Positive')
axs[1].set_title('Neutral')
axs[2].set_title('Negative')
plt.tight_layout()
plt.show()

from transformers import AutoTokenizer, AutoModelForSequenceClassification
from scipy.special import softmax

MODEL = f"cardiffnlp/twitter-roberta-base-sentiment"
tokenizer = AutoTokenizer.from_pretrained(MODEL)
model = AutoModelForSequenceClassification.from_pretrained(MODEL)

print(example)
sia.polarity_scores(example)

#Run using Roberta Model
encoded_text = tokenizer(example, return_tensors='pt')
output = model(**encoded_text)
scores = output[0][0].detach().numpy()
scores = softmax(scores)
scores_dict = {
    'roberta_neg' : scores[0],
    'roberta_neu' : scores[1],
    'roberta_pos' : scores[2]
}
print(scores_dict)

def polarity_scores_roberta(example):
    encoded_text = tokenizer(example, return_tensors='pt')
    output = model(**encoded_text)
    scores = output[0][0].detach().numpy()
    scores = softmax(scores)
    scores_dict = {
        'roberta_neg' : scores[0],
        'roberta_neu' : scores[1],
        'roberta_pos' : scores[2]
    }
    return scores_dict

res = {}
for i, row in tqdm(df.iterrows(), total=len(df)):
    try:
        text = row['Text']
        myid = row['Id']

        # Calculate VADER scores
        vader_result = sia.polarity_scores(text)
        vader_result_resume = {}
        for key, value in vader_result.items():
            vader_result_resume[f"vader_{key}"] = value

        # Calculate Roberta scores
        roberta_result = polarity_scores_roberta(text)

        # Combine results
        both = {**vader_result_resume, **roberta_result}

        # Store the combined results
        res[myid] = both

    except RuntimeError:
        print(f'Broken for id {myid}')

results_df = pd.DataFrame(res).T
results_df = results_df.reset_index().rename(columns={'index': 'Id'})
results_df = results_df.merge(df, how='left')

"""Compare scores between Models"""

sns.pairplot(data=results_df,
             vars=['vader_neg', 'vader_neu', 'vader_pos',
                   'roberta_neg', 'roberta_neu', 'roberta_pos'],
             hue='Score',
             palette='deep')
plt.show()

"""Review Examples
  
"""

results_df.query('Score == 1').sort_values('roberta_pos', ascending = False)['Text'].values[0]

results_df.query('Score == 1')\
    .sort_values('vader_neg', ascending = False)['Text'].values[0]

#Negative sentiment 5 stars review
results_df.query('Score == 5').sort_values('roberta_pos', ascending = False)['Text'].values[0]

results_df.query('Score == 5')\
    .sort_values('vader_neg', ascending = False)['Text'].values[0]

from transformers import pipeline

sent_pipeline = pipeline("sentiment-analysis")

sent_pipeline('Sentiment Analysis is Average')